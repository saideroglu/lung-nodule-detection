# -*- coding: utf-8 -*-
"""luna16_visualize.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12e6HoG-A2T94uLNu7QgsM4xZsyxfN6C7
"""

from google.colab import drive
drive.mount('/content/drive')

import SimpleITK as sitk
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

import os
import shutil

import tensorflow as tf
from tqdm.notebook import tqdm
from tensorflow.keras.models import model_from_json

"""## Functions"""

def load_itkfilewithtrucation(filename, upper=200, lower=-200):
    srcitkimage = sitk.Cast(sitk.ReadImage(filename), sitk.sitkFloat32)
    srcitkimagearray = sitk.GetArrayFromImage(srcitkimage)
    srcitkimagearray[srcitkimagearray > upper] = upper
    srcitkimagearray[srcitkimagearray < lower] = lower
    sitktructedimage = sitk.GetImageFromArray(srcitkimagearray)
    origin = np.array(srcitkimage.GetOrigin())
    spacing = np.array(srcitkimage.GetSpacing())
    sitktructedimage.SetSpacing(spacing)
    sitktructedimage.SetOrigin(origin)
    rescalFilt = sitk.RescaleIntensityImageFilter()
    rescalFilt.SetOutputMaximum(255)
    rescalFilt.SetOutputMinimum(0)
    itkimage = rescalFilt.Execute(sitk.Cast(sitktructedimage, sitk.sitkFloat32))
    return itkimage

def load_itk_version2(img_file):
    itk_img = load_itkfilewithtrucation(img_file, 600, -1000)
    img_array = sitk.GetArrayFromImage(itk_img)

    origin = np.array(itk_img.GetOrigin())
    spacing = np.array(itk_img.GetSpacing())

    return img_array, origin, spacing

def world_to_image_coords(world_coords, origin, spacing):
    return np.rint((world_coords - origin) / spacing).astype(int)

def plot_slice_with_annotations(ct_array, annotations, slice_index):
    plt.figure(figsize=(10, 10))
    plt.imshow(ct_array[slice_index], cmap='gray')

    slice_annotations = annotations[annotations['imageZ'] == slice_index]
    for _, row in slice_annotations.iterrows():
        x, y = row['imageX'], row['imageY']
        box_size = 32
        print(f'\nAnnotation at slice {slice_index}: x={x}, y={y}')
        plt.gca().add_patch(plt.Rectangle((x - box_size / 2, y - box_size / 2), box_size, box_size, linewidth=1, edgecolor='r', facecolor='none'))
        #plt.text(x, y, '32x32', color='red', fontsize=12)

    plt.title(f'Slice {slice_index} with Annotations')
    plt.show()

def load_model(json_path, weights_path):
    with open(json_path, 'r') as json_file:
        loaded_model_json = json_file.read()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights(weights_path)
    return loaded_model

def predict_nodule(model, cube):
    prediction = model.predict(cube[np.newaxis, ..., np.newaxis])
    return prediction

def show_images(images, cols=1, titles=None):
    assert((titles is None) or (len(images) == len(titles)))
    n_images = len(images)
    if titles is None:
        titles = ['Image (%d)' % i for i in range(1, n_images + 1)]
    fig = plt.figure()
    for n, (image, title) in enumerate(zip(images, titles)):
        a = fig.add_subplot(cols, int(np.ceil(n_images / float(cols))), n + 1)
        if image.ndim == 2:
            plt.gray()
        plt.imshow(image)
        a.set_title(title)
    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)
    plt.show()

def show_center_slice(image_data):
    central_slice = image_data[16, :, :]
    plt.figure(figsize=(8, 8))
    plt.imshow(central_slice, cmap='gray')
    plt.colorbar()
    plt.show()

def show_all_slice(image_data):
    num_slices = image_data.shape[0]
    fig, axes = plt.subplots(4, 8, figsize=(20, 10))  # rows and columns

    for i in range(num_slices):
        ax = axes[i // 8, i % 8]
        ax.imshow(image_data[i, :, :], cmap='gray')
        ax.set_title(f'Slice {i}')
        ax.axis('off')

    plt.tight_layout()
    plt.show()

def format_probabilities(prediction_array, decimal_places=4):
    if not isinstance(prediction_array, np.ndarray):
        raise ValueError("The input must be a numpy array.")

    if prediction_array.ndim != 2 or prediction_array.shape[0] != 1:
        raise ValueError("The input array must be a 2D array with a single prediction.")

    probabilities = prediction_array[0]
    format_string = f"{{:.{decimal_places}f}}"
    formatted_probabilities = [format_string.format(prob) for prob in probabilities]

    return formatted_probabilities

def cropND(img, bounding):
    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))
    end = tuple(map(operator.add, start, bounding))
    slices = tuple(map(slice, start, end))
    return img[slices]

"""## Bounding Boxes in the CT"""

ct_scan_path = '/content/drive/MyDrive/Luna16/subset9/1.3.6.1.4.1.14519.5.2.1.6279.6001.112767175295249119452142211437.mhd'
ct_scan_array, origin, spacing = load_itk_version2(ct_scan_path)

print(f"CT Scan Shape: {ct_scan_array.shape}")
print(f"Origin: {origin}")
print(f"Spacing: {spacing}")

total_slices = ct_scan_array.shape[0]
print(f"Total slices: {total_slices}")

annotations_path = '/content/drive/MyDrive/Luna16/annotations.csv'
annotations = pd.read_csv(annotations_path)

last_slash_index = ct_scan_path.rfind('/')
mhd_index = ct_scan_path.rfind('.mhd')
seriesuid = ct_scan_path[last_slash_index + 1 : mhd_index]
annotations = annotations[annotations['seriesuid'] == seriesuid]

# Convert coordinates from world to image
annotations.loc[:, 'imageX'] = world_to_image_coords(annotations['coordX'].values, origin[0], spacing[0])
annotations.loc[:, 'imageY'] = world_to_image_coords(annotations['coordY'].values, origin[1], spacing[1])
annotations.loc[:, 'imageZ'] = world_to_image_coords(annotations['coordZ'].values, origin[2], spacing[2])

print(f"\nTransformed annotations:\n {annotations}")

unique_slices = annotations['imageZ'].unique()
for slice_index in unique_slices:
    plot_slice_with_annotations(ct_scan_array, annotations, slice_index)

"""## Candidates for the CT"""

model = load_model('/content/drive/MyDrive/models/vgg11_3d_0531_011753_D1.json',
                   '/content/drive/MyDrive/models/vgg11_3d_0531_011753_D1.h5')

nodules_folder = '/content/drive/MyDrive/candidates_32/extracted_output/content/output_subset9/1/' # Select the candidate subset used for model testing
nonnodules_folder = '/content/drive/MyDrive/candidates_32/extracted_output/content/output_subset9/0/'

images = []
titles = []
for filename in os.listdir(nodules_folder):
    if filename.endswith('.npy'):

        candidate_seriesuid = filename.split('_')[3]
        if candidate_seriesuid == seriesuid:
            print("Nodule candidate:", filename)
            image_data = np.load(nodules_folder + filename)
            central_slice = image_data[16, :, :]

            '''
            plt.figure(figsize=(8, 8))
            plt.imshow(central_slice, cmap='gray')  # Assuming you want to plot the central slice along the z-axis
            plt.colorbar()
            plt.title('Slice of 32x32x32 Image')
            plt.show()
            '''

            images.append(central_slice)
            titles.append(filename)

show_images(images, 2)

candidade_name = '9_29_82_1.3.6.1.4.1.14519.5.2.1.6279.6001.112767175295249119452142211437_42.10790404_55.26200082_-84.33812204_1.npy'

candidate_path = nodules_folder + candidade_name

sample_cube = np.load(candidate_path)

show_center_slice(sample_cube)

prediction = predict_nodule(model, sample_cube)
print("Prediction array:", prediction) # The first value indicates the probability of nonnodule, the second indicates the probability of nodule

formatted_probabilities = format_probabilities(prediction) # as 0,XXXX
print(formatted_probabilities)

show_all_slice(sample_cube)

"""## Augmentation Visualization"""

import operator
from albumentations import Compose, RandomRotate90, Transpose, RandomBrightnessContrast, VerticalFlip, HorizontalFlip, RandomScale

augm = Compose([
    RandomRotate90(),
    Transpose(),
    RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),
    VerticalFlip(p=0.7),
    HorizontalFlip(p=0.7),
    RandomScale(scale_limit=0.3)
])

images[1].shape

candidade_name = '9_78_446_1.3.6.1.4.1.14519.5.2.1.6279.6001.114914167428485563471327801935_-34.1029155_-9.53744_-37.6650075_1.npy'

candidate_path = nodules_folder + candidade_name

image_data = np.load(candidate_path)
show_center_slice(image_data)

show_all_slice(image_data)

im = np.load(candidate_path)
save_path = '/content/aug_sample/'
os.makedirs(save_path, exist_ok=True)
num_aug_iterations = 20
for r in range(num_aug_iterations):
    image_ = augm(image=im.astype(np.uint8))['image']

    #if image_.shape[0] != 32:
        #image_ = cropND(image_, (32, 32, 32))

    file_name = f"aug_{r}.npy"
    np.save(os.path.join('/content/aug/', file_name), image_)

image_data = np.load('/content/aug_sample/aug_0.npy')
show_center_slice(image_data)

aug_image = np.load('/content/aug_sample/aug_1.npy')
show_all_slice(aug_image)

aug_images = []
files = [os.path.join(save_path, f) for f in os.listdir(save_path) if f.endswith('.npy')]
for file_path in files:
    im = np.load(file_path)
    center_slice = im[16, :, :]
    aug_images.append(center_slice)

show_images(aug_images, 4)