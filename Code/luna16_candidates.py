# -*- coding: utf-8 -*-
"""luna16_candidates.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QvMfl-zmadUE6X4bb6BZ1EcQDZI20xOh
"""

from google.colab import drive
drive.mount('/content/drive')

import SimpleITK as sitk
import numpy as np
import pandas as pd
import os
import shutil
from glob import glob
from tqdm.notebook import tqdm
import random
import zipfile
import operator
from albumentations import Compose, RandomRotate90, Transpose, RandomBrightnessContrast, VerticalFlip, HorizontalFlip, RandomScale

"""## Functions"""

def load_itkfilewithtrucation(filename, upper=200, lower=-200):
    # 1,tructed outside of liver value
    srcitkimage = sitk.Cast(sitk.ReadImage(filename), sitk.sitkFloat32)
    srcitkimagearray = sitk.GetArrayFromImage(srcitkimage)
    srcitkimagearray[srcitkimagearray > upper] = upper
    srcitkimagearray[srcitkimagearray < lower] = lower
    # 2,get tructed outside of liver value image
    sitktructedimage = sitk.GetImageFromArray(srcitkimagearray)
    origin = np.array(srcitkimage.GetOrigin())
    spacing = np.array(srcitkimage.GetSpacing())
    sitktructedimage.SetSpacing(spacing)
    sitktructedimage.SetOrigin(origin)
    # 3 normalization value to 0-255
    rescalFilt = sitk.RescaleIntensityImageFilter()
    rescalFilt.SetOutputMaximum(255)
    rescalFilt.SetOutputMinimum(0)
    itkimage = rescalFilt.Execute(sitk.Cast(sitktructedimage, sitk.sitkFloat32))
    return itkimage

def get_cube_from_img(img3d, center, block_size):
    # get roi(z,y,z) image and in order the out of img3d(z,y,x)range
    center_z = center[0]
    center_y = center[1]
    center_x = center[2]
    start_x = max(center_x - block_size / 2, 0)
    if start_x + block_size > img3d.shape[2]:
        start_x = img3d.shape[2] - block_size
    start_y = max(center_y - block_size / 2, 0)
    if start_y + block_size > img3d.shape[1]:
        start_y = img3d.shape[1] - block_size
    start_z = max(center_z - block_size / 2, 0)
    if start_z + block_size > img3d.shape[0]:
        start_z = img3d.shape[0] - block_size
    start_z = int(start_z)
    start_y = int(start_y)
    start_x = int(start_x)
    roi_img3d = img3d[start_z:start_z + block_size, start_y:start_y + block_size, start_x:start_x + block_size]
    return roi_img3d

def load_itk(img_file):
    itk_img = load_itkfilewithtrucation(img_file, 600, -1000)
    img_array = sitk.GetArrayFromImage(itk_img)

    origin = np.array(itk_img.GetOrigin())
    spacing = np.array(itk_img.GetSpacing())

    return img_array, origin, spacing

def get_file_paths(folder):
    neg_path = os.path.join(data_dir, folder, neg_label)
    pos_path = os.path.join(data_dir, folder, pos_label)
    neg_files = [os.path.join(neg_path, file) for file in os.listdir(neg_path) if file.endswith('.npy')]
    pos_files = [os.path.join(pos_path, file) for file in os.listdir(pos_path) if file.endswith('.npy')]
    return neg_files, pos_files

def create_csv(paths, label, filename):
    df = pd.DataFrame(paths, columns=['filename'])
    df['class'] = label
    df.to_csv(filename, index=False)

def cropND(img, bounding):
    start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))
    end = tuple(map(operator.add, start, bounding))
    slices = tuple(map(slice, start, end))
    return img[slices]

"""## Save Candidates"""

num_subsets = 10
image_size = 32

for subsetindex in tqdm(range(num_subsets)):
    luna_path = "/content/"
    luna_subset_path = luna_path + "subset" + str(subsetindex) + "/"
    output_path = "/content/drive/MyDrive/candidates_32/"
    file_list = glob(luna_subset_path + "*.mhd")

    df_node = pd.read_csv('/content/candidates_V2.csv') # Change this with path to candidates csv file

    df_node["file"] = df_node["seriesuid"].map(lambda file_name: [f for f in file_list if file_name in f][0] if any(file_name in f for f in file_list) else None)
    df_node = df_node.dropna()

    for fcount, img_file in enumerate(tqdm(file_list)):
        temp_df = df_node[df_node["file"] == img_file]

        if temp_df.shape[0] > 0:
            img_array, origin, spacing = load_itk(img_file)

            index = 0
            for node_idx, row in temp_df.iterrows():
                x, y, z = row["coordX"], row["coordY"], row["coordZ"]
                label = row["class"]

                center = np.array([x, y, z])
                v_center = np.rint((center - origin) / spacing)

                # convert x,y,z order  to z,y,x
                v_center[0], v_center[1], v_center[2] = v_center[2], v_center[1], v_center[0]

                node_cube = get_cube_from_img(img_array, v_center, image_size)
                node_cube.astype(np.uint8)

                if label == 1:
                    filepath = output_path + "1/"
                    if not os.path.exists(filepath):
                        os.makedirs(filepath)
                    filename = str(subsetindex) + "_" + str(fcount) + "_" + str(index) + '_' + str(row['seriesuid']) + '_' + str(x) + '_' + str(y) + '_' + str(z) +'_'+ str(label)
                    np.save(filepath + filename + ".npy", node_cube)

                if label == 0:
                    filepath = output_path + "0/"
                    if not os.path.exists(filepath):
                        os.makedirs(filepath)
                    filename = str(subsetindex) + "_" + str(fcount) + "_" + str(index) + '_' + str(row['seriesuid']) + '_' + str(x) + '_' + str(y) + '_' + str(z) +'_'+ str(label)
                    np.save(filepath + filename + ".npy", node_cube)
                index += 1

"""## Split Data"""

data_dir = '/content/content/'  # Candidates location
folders = [f'output_subset{i}' for i in range(10)] # Candidates subsets (folder names)
neg_label = '0'
pos_label = '1'
num_aug_iterations = 19

# Select folders for train, validation and test
train_folders = folders[:8]
val_folder = folders[8]
test_folder = folders[9]

train_neg_paths, train_pos_paths = [], []
for folder in train_folders:
    neg_files, pos_files = get_file_paths(folder)
    train_neg_paths.extend(neg_files)
    train_pos_paths.extend(pos_files)

val_neg_paths, val_pos_paths = get_file_paths(val_folder)
test_neg_paths, test_pos_paths = get_file_paths(test_folder)

# Balance validation and testing data
balanced_train_neg_paths = random.sample(train_neg_paths, len(train_pos_paths)*(num_aug_iterations+1))
balanced_val_neg_paths = random.sample(val_neg_paths, len(val_pos_paths)*(num_aug_iterations+1))
balanced_test_neg_paths = random.sample(test_neg_paths, len(test_pos_paths))

create_csv(train_pos_paths, 1, 'training_1.csv')
create_csv(balanced_train_neg_paths, 0, 'training_0.csv')
create_csv(val_pos_paths, 1, 'validation_1.csv')
create_csv(balanced_val_neg_paths, 0, 'validation_0.csv')
create_csv(test_pos_paths, 1, 'testing_1.csv')
create_csv(balanced_test_neg_paths, 0, 'testing_0.csv')

"""## Augmentation"""

train_df = pd.read_csv('/content/training_1.csv')
val_df = pd.read_csv('/content/validation_1.csv')

train_files = train_df['filename'].tolist()
val_files = val_df['filename'].tolist()

augm_save_path = '/content/augmented/'
train_save_path = os.path.join(augm_save_path, 'train')
val_save_path = os.path.join(augm_save_path, 'val')

os.makedirs(train_save_path, exist_ok=True)
os.makedirs(val_save_path, exist_ok=True)

augm = Compose([
    RandomRotate90(),
    Transpose(),
    RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),
    VerticalFlip(p=0.7),
    HorizontalFlip(p=0.7),
    RandomScale(scale_limit=0.3)
])

train_aug_paths = []
for idx, file_path in enumerate(train_files):
    im = np.load(file_path)
    for r in range(num_aug_iterations):
        image_ = augm(image=im.astype(np.uint8))['image']
        if image_.shape[0] != 32:
            image_ = cropND(image_, (32, 32, 32))
        file_name = f"{idx}_{r}.npy"
        train_aug_paths.append(os.path.join(train_save_path, file_name))
        np.save(os.path.join(train_save_path, file_name), image_)

val_aug_paths = []
for idx, file_path in enumerate(val_files):
    im = np.load(file_path)
    for r in range(num_aug_iterations):
        image_ = augm(image=im.astype(np.uint8))['image']
        if image_.shape[0] != 32:
            image_ = cropND(image_, (32, 32, 32))
        file_name = f"{idx}_{r}.npy"
        val_aug_paths.append(os.path.join(val_save_path, file_name))
        np.save(os.path.join(val_save_path, file_name), image_)

create_csv(train_aug_paths, 1, 'training_aug.csv')
create_csv(val_aug_paths, 1, 'validation_aug.csv')