# -*- coding: utf-8 -*-
"""luna16_model_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xh3FxTPcCITkOxMsH4pmDDDTUU0TMYdl
"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow import keras
from keras import optimizers
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution3D, MaxPooling3D, Convolution2D, AveragePooling2D, MaxPooling2D, ZeroPadding3D, ZeroPadding2D
from keras.utils import to_categorical
from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from keras.models import model_from_json

import cv2
from tqdm.notebook import tqdm
import pandas as pd
import numpy as np
import os
import shutil
import zipfile
import gc
from datetime import datetime

from scipy import stats
from sklearn.utils import shuffle
from sklearn.utils.multiclass import unique_labels
from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score
import matplotlib.pyplot as plt

"""## Utilities"""

def data_generator(data_df, batch_size=32):
    num_samples = data_df.shape[0]
    num_batches = num_samples // batch_size

    while True:
        data_df = data_df.sample(frac=1)  # Shuffle the dataframe
        for batch_index in range(num_batches):
            batch_df = data_df.iloc[batch_index * batch_size : (batch_index + 1) * batch_size]
            X_batch, Y_batch = [], []
            for _, image in batch_df.iterrows():
                lung_img = np.load(image['filename'])
                if lung_img.shape[0] == 32:
                    X = lung_img.reshape((32, 32, 32, 1))
                    X_batch.append(X)
                    Y_batch.append(int(image['class']))
            X_batch, Y_batch = np.array(X_batch), np.array(Y_batch)
            Y_batch = to_categorical(Y_batch, 2)
            yield X_batch, Y_batch

def plot_confusion_matrix(y_true, y_pred,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    classes = unique_labels(y_true, y_pred)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

"""## Models"""

def CNNT5_3D():
    model = keras.Sequential()
    model.add(Convolution3D(filters=8, kernel_size=(5, 5, 5), strides=1, activation='relu', input_shape=(32,32,32,1)))
    model.add(MaxPooling3D(pool_size=(2, 2,2), strides=2))
    model.add(Convolution3D(filters=16, kernel_size=(5, 5, 5),strides=1, activation='relu'))
    model.add(MaxPooling3D(pool_size=(2, 2,2), strides=2))
    model.add(Flatten())
    model.add(Dense(units=150, activation='relu'))
    model.add(Dropout(0.3))
    model.add(Dense(units=100, activation='relu'))
    model.add(Dropout(0.3))
    model.add(Dense(units=50, activation='relu'))
    model.add(Dense(units=2, activation = 'softmax'))

    return model

def VGG11_3D(weights_path=None):
    model = Sequential()
    model.add(ZeroPadding3D((0,1,1), input_shape=(32,32,32,1)))
    model.add(Convolution3D(64, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2), data_format='channels_last'))

    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(128, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2), data_format='channels_last'))

    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(256, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(256, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2), data_format='channels_last'))

    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(512, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(512, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), data_format='channels_last'))

    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(512, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(512, (3,3,3), activation='relu', data_format='channels_last'))
    model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), data_format='channels_last'))

    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(2, activation='softmax'))

    return model

"""## Data Generation"""

train_non = pd.read_csv('/content/training_0.csv')
val_non = pd.read_csv('/content/validation_0.csv')
test_non = pd.read_csv('//content/testing_0.csv')
train_nod = pd.read_csv('/content/training_1.csv')
val_nod = pd.read_csv('/content/validation_1.csv')
test_nod = pd.read_csv('/content/testing_1.csv')
train_aug = pd.read_csv('/content/training_aug.csv')
val_aug = pd.read_csv('/content/validation_aug.csv')

candidates_train = pd.concat([train_non, train_nod, train_aug])
candidates_val = pd.concat([val_non, val_nod, val_aug])
candidates_test = pd.concat([test_non, test_nod])

batch_size = 32

train_generator = data_generator(candidates_train, batch_size)
val_generator = data_generator(candidates_val, batch_size)
test_generator = data_generator(candidates_test, batch_size)

"""## Train model"""

opt = keras.optimizers.Adam(learning_rate=0.0001)
# opt = keras.optimizers.RMSprop(learning_rate=0.0001, rho=0.95)
model = VGG11_3D()

model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

callback = [EarlyStopping(monitor='val_loss', patience=7),
            ReduceLROnPlateau(patience=5, verbose=1)]


history = model.fit(train_generator,
                    steps_per_epoch=len(candidates_train) // batch_size,
                    epochs=30,
                    validation_data=val_generator,
                    validation_steps=len(candidates_val) // batch_size,
                    callbacks=callback)

history.history.keys()

df_logs = pd.DataFrame(columns=['val_accuracy', 'val_loss', 'train_loss', 'accuracy'])
df_logs['val_acc'] =history.history['val_accuracy']
df_logs['val_loss'] = history.history['val_loss']
df_logs['train_acc'] = history.history['accuracy']
df_logs['train_loss'] = history.history['loss']

if not os.path.exists('/content/drive/MyDrive/logs/models'):
    os.makedirs('/content/drive/MyDrive/logs/models')

file_prefix = 'vgg11_3d'
timestamp = datetime.now().strftime("%m%d_%H%M%S")
dataset_config = 'D1'

'/content/drive/MyDrive/logs/models/{}_{}_{}.csv'.format(file_prefix, timestamp, dataset_config)

df_logs.to_csv('/content/drive/MyDrive/logs/models/{}_{}_{}.csv'.format(file_prefix, timestamp, dataset_config), index=False)

LOGS = '/content/drive/MyDrive/models/'
model_json = model.to_json()
with open(LOGS + "{}_{}_{}.json".format(file_prefix, timestamp, dataset_config), "w") as json_file:
    json_file.write(model_json)
model.save_weights(LOGS + '{}_{}_{}.h5'.format(file_prefix, timestamp, dataset_config))

"""## Test the trained model"""

# Collecting true labels and predictions from the test generator
y_true = []
y_pred = []

for X_batch, Y_batch in test_generator:
    predictions = model.predict(X_batch)
    y_true.extend(np.argmax(Y_batch, axis=1))
    y_pred.extend(np.argmax(predictions, axis=1))

    if len(y_true) >= len(candidates_test):
        break

y_true = np.array(y_true)
y_pred = np.array(y_pred)

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Nonnodule', 'Nodule']))

plot_confusion_matrix(y_true, y_pred, normalize=False, title='Confusion Matrix')
plt.show()

plot_confusion_matrix(y_true, y_pred, normalize=True, title='Normalized Confusion Matrix')
plt.show()

"""## Test from scratch"""

test_non = pd.read_csv('//content/testing_0.csv')
test_nod = pd.read_csv('/content/testing_1.csv')

candidates_test = pd.concat([test_non, test_nod])

batch_size = 32

test_generator = data_generator(candidates_test, batch_size)

LOGS = '/content/drive/MyDrive/models/'
json_file = open('/content/drive/MyDrive/models/cnnt5_3d_0526_084002_D1.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights('/content/drive/MyDrive/models/cnnt5_3d_0526_084002_D1.h5')

y_true = []
y_pred = []

for X_batch, Y_batch in test_generator:
    predictions = loaded_model.predict(X_batch)
    y_true.extend(np.argmax(Y_batch, axis=1))
    y_pred.extend(np.argmax(predictions, axis=1))

    if len(y_true) >= len(candidates_test):
        break

y_true = np.array(y_true)
y_pred = np.array(y_pred)

cm = confusion_matrix(y_true, y_pred)

print("Classification Report:\n", classification_report(y_true, y_pred, target_names=['Nonnodule', 'Nodule']))

plot_confusion_matrix(y_true, y_pred, normalize=False, title='Confusion Matrix')
plt.show()

plot_confusion_matrix(y_true, y_pred, normalize=True, title='Normalized Confusion Matrix')
plt.show()